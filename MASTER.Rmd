---
title: "Final Project - MASTER"
last updated: 3/13/18
---

###Data Cleaning and Analysis Tutorial
  
This tutorial will lead you through the steps of cleaning and analyzing survey data in R. This analysis is a part of a larger research project examining the organizing structure and capacity of food pantries. You will find instructions both in the text before each code chunk as well as in comment form within the chunks.
  
#####About the Data  
The data used for this tutuorial is from a survey of emergency food assistance providers in the Detroit Metropolitan area from 2012 and 2013. The data was collected at the University of Chicago by a trained interviewer who administered the surveys either by phone or via an online survey tool. Survey questions asked about the organizational characteristics of each agency such as the hours of operation, types of programs offered, and staffing structure. We will also use population data from the American Community Survey from 2010-2014. For the purpose of this tutorial, our analysis will focus on a subset of this data with variables describing the types of programs offered, geographic location, and demographic characteristics.

```{r Setup, warning=FALSE, message=FALSE}
# Libraries
library(readxl) #used
library(dplyr)
library(moments)
library(stringr)
library(scales)
library(ggplot2)
library(jsonlite)
library(utils)
library(rgdal)
library(readstata13)
library(RColorBrewer)
library(classInt)
library(ggmap)
library(googleway)
library(pander)

# Functions
getMode = function(aColumn){
  freqTable=table(aColumn)
  maxFrequency=max(freqTable)
  names(freqTable[freqTable==maxFrequency])
}
```

####Step 1: Create Dataset

The survey data comes in three different Excel files: inital responses from 2/15/13, recoded questions, and addresses. We need to import each of these indvidually and then merge them together. All of the raw data files are stored on Github and we will temporarily download them for our analysis.

#####Import Survey Data

First we need to import the survey data. We will use the "readxl" package, so make sure this package is installed the first time you use it. We will import the three Excel files individually and place them in separate data frames.

```{r Import Data: Initial, warning=FALSE, message=FALSE}
# Load library
# First time you need to install "readxl": install.packages("readxl")
library(readxl)

# Import initial survey responses from 2_15_13
temp = tempfile(fileext = '.xlsx') #extension for Excel files
dataURL <- "https://github.com/lrsulli/Project/raw/master/Data/fp_survey_2_15_13.xlsx" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_initial = read_excel(temp, sheet = 1) #get data
```

```{r Import Data: Recodes, warning=FALSE, message=FALSE}
# Load library
library(readxl)

# Recode file for Q12 and Q22 to Q25
temp = tempfile(fileext = '.xlsx') #extension for Excel fie
dataURL <- "https://github.com/lrsulli/Project/raw/master/Data/recode_Q12_Q22toQ25.xlsx" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_recode = read_excel(temp, sheet = 1) #get data
```

```{r Import Data: Addresses, warning=FALSE, message=FALSE}
# Load library
library(readxl)

# Address list data file
temp = tempfile(fileext = '.xlsx') #extension for Excel fie
dataURL <- "https://github.com/lrsulli/Project/raw/master/Data/address_list_5_20_13.xlsx" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_address = read_excel(temp, sheet = 1) #get data
```

#####Merge Survey Data

Now that we have each Excel file in a data frame we need to merge them into one data frame for our analysis. To do this we need to have a common variable in each data frame, in this case a unique "STUDYID" was given to each provider when they were surveyed. We will merge using this identifyer. We will also prepare each data frame for merging by renaming variables where necessary and only keeping a subset of the variables to keep things simplier.  

First, we will merge the intial survey responses with the recode file:

```{r Merge Data: Recodes, warning=FALSE, message=FALSE}
# Prepare recode file
names(data_recode) #Check names and see what the identifyer variable is called

# We don't need all of these varaibles so we will only keep the necessary ones:
data_recode = data_recode[,c(1,5:6,14:15,19:20)] #only keep necessary variables

# Rename the identifyer variable so it matches the initial data set to keep things simplier:
names(data_recode)[1] <- "STUDYID" #rename to match initial data set

# Merge recode file with initial data set
data = merge(data_initial, data_recode, by="STUDYID")
```

Then we add the address data:

```{r Merge Data: Addresses, warning=FALSE, message=FALSE}
# Prepare address list file
names(data_address)[1] <- "STUDYID" #rename to match inital data set

# Merge address list with initial data set and recodes
data = merge(data, data_address, by="STUDYID")

data = data.frame(data) #convert to data frame
```

#####Import Census Data

We now need to import the Census data so we can analyze the demographics of the populations that the providers serve. This data comes in Stata, or .dta, files which are also stored in Github. We import them the same way as the survey data, just with a different extension. Again, we will temporairly dowload each file and store them separately in different data frames.  

```{r Import Data: Census 1, warning=FALSE, message=FALSE}
# Import first of three census data files
temp = tempfile(fileext = '.dta') #extension for Stata data file
dataURL <- "https://github.com/lrsulli/Project/raw/master/Population_Data%204_7_17.dta" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_census1 = read.dta13(temp) #get data
```

```{r Import Data: Census 2, warning=FALSE, message=FALSE}
# Import second of three census data files
temp = tempfile(fileext = '.dta') #extension for Stata data file
dataURL <- "https://github.com/lrsulli/Project/raw/master/Census_Data%204_28_17.dta" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_census2 = read.dta13(temp) #get data
```

```{r Import Data: Census 3, warning=FALSE, message=FALSE}
# Import third of three census data files
temp = tempfile(fileext = '.dta') #extension for Stata data file
dataURL<-"https://github.com/lrsulli/Project/raw/master/tract10detroit_povertypop_123mile.dta" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

data_census3 = read.dta13(temp) #get data
```

#####Merge Census Data

We then need to merge the census data files together as they contain different demographic variables that we need. We will again merge the data frames on a similar variable. For the census data frames this variable will be the census tract number. Then, to add the demographic variables to the survey data we will use the STUDYID variable again, as it is included in one of the census data files.  

First, merge the census data frames:

```{r Merge Data: Census, warning=FALSE, message=FALSE}
# Merge first two census data files (Census1 and Census2)
data_census = merge(data_census1, data_census2, by="tr10fips", all=T) #keep all tracts

# Merge third census data file (Census3 with Census1 and Census2)
data_census = merge(data_census, data_census3, by="tr10fips", all=T) #keep all tracts

data_census = data.frame(data_census) #convert to data frame
```

Then add the census data to the survey data (note that the census data contains all census tracts in Michigan, but we only need the tracts that have food providers in them):

```{r Merge Data: Census with Survey Data, warning=FALSE, message=FALSE}
# Merge Census data and survey data
data = merge(data, data_census, by='STUDYID') #only keep tracts that have organizations

data = data.frame(data) #convert to data frame
```

#####Clean Data Set

Let's check to see what we have:

```{r Check Variable Names, warning=FALSE, message=FALSE, eval=FALSE}
# Check variable names of data
names(data)
```

We don't need all of these variables for our analysis. To make things simpler, we will only keep what we need. We will also make a copy of the original data frame just in case we miss something and want to go back and get it later.

```{r Drop Variables, warning=FALSE, message=FALSE}
# Create a copy of original data set
data_copy = data

# Only keep necessary variables
data = data_copy[,c('tr10fips','STUDYID','Q5','Q6_1','Q6_2','Q6_3','Q6_4','Q6_5','Q7','Q8_1','Q8_2','Q8_3','Q8_4','Q8_5','Q8_6','Q8_7','Q8_8','Q9','Q10_1','Q10_2','Q10_3','Q10_4','Q10_5','Q14','Q15_1','Q15_2','Q15_3','Q15_4','Q15_5','Q15_6','Q15_7','Q15_8','Q15_9','Q15_10','Q15_11','Q15_12','Q15_13','Q12RC','Street.Address','City','State','Zip','County','povpop10071','povpopd71','povpop_1m',"povpopd711mile","povpop_3m","povpopd713mile","nhwht71","pop71","nhwht711mile","nhwht713mile","blk71","blk711mile","blk713mile","hsp71","hsp711mile","hsp713mile","hhsnapfam271","hhsnapfam171","hhsnapfam2711mile","hh711mile","hhsnapfam2713mile","hh713mile")]
```

When we look at the names of the variables, we notice that they are not very helpful in describing the variables themselves. Let's rename the variables to make our analysis easier.

```{r Rename Variables, warning=FALSE, message=FALSE}
# Check variable names of data
names(data)

# Rename identification variables
names(data)[1] <- "tract"
names(data)[2] <- "id"

# Rename types of meal programs
names(data)[3] <- "meals"
names(data)[4] <- "hot_meals"
names(data)[5] <- "home_meals" #Home delivered meals
names(data)[6] <- "community_kitchen"
names(data)[7] <- "child_meals"
names(data)[8] <- "meal_other" #Offer other types of meal programs

# Rename types of grocery programs
names(data)[9] <- "groceries"
names(data)[10] <- "pantry"
names(data)[11] <- "backpack"
names(data)[12] <- "home_groceries" #Home delivered groceries
names(data)[13] <- "mobile_pantry"
names(data)[14] <- "mobile_market"
names(data)[15] <- "supply_other" #Supply food to other programs
names(data)[16] <- "community_garden"
names(data)[17] <- "groceries_other" #Offer other types of grocery programs

# Rename types of food related benefit programs
names(data)[18] <- "food_ben" #Offers food-related benefits
names(data)[19] <- "snap"
names(data)[20] <- "wic"
names(data)[21] <- "school" #School lunch or breakfast
names(data)[22] <- "gift" #Gift card or voucher
names(data)[23] <- "food_ben_other" #Offer other types of food-related benefits

# Rename types of non-food related benefit programs
names(data)[24] <- "nonfood_ben" #Offers non-food related benefits
names(data)[25] <- "job" #Job training or assistance
names(data)[26] <- "house" #Housing assistance
names(data)[27] <- "utility"
names(data)[28] <- "legal"
names(data)[29] <- "educ" #GED or education assistance
names(data)[30] <- "health"
names(data)[31] <- "counseling"
names(data)[32] <- "trans" #Transportation assistance
names(data)[33] <- "cloth" #Clothing or furniture
names(data)[34] <- "ref" #Referrals to other programs
names(data)[35] <- "medicaid" #Medicaid or CHIP
names(data)[36] <- "money" #Financial, tax prep, budgeting
names(data)[37] <- "nonfood_ben_other" #Offer other types of non-food related benefits

# Rename number of clients served per month
names(data)[38] <- "clients"
```

#####Create New Variables

We will need some of our demographic variables as rates for our analysis. To do this, we need to create new variables using the "mutate" function. We will add these to our main data frame.

```{r Generate Census Variables, warning=FALSE, message=FALSE}
# Generate poverty rate variables
data <- mutate(data, pov_rateT = povpop10071 / povpopd71) #Rate within census tract
data <- mutate(data, pov_rate1 = povpop_1m / povpopd711mile) #Rate within 1 mile
data <- mutate(data, pov_rate3 = povpop_3m / povpopd713mile) #Rate within 3 miles

# Reconicle naming discrepancies between census data sets
# Will use poverty rate within 1 mile for missing within tract poverty rates
data_census$povpop10071[is.na(data_census$povpop10071)] <- 0 #Convert NA's to 0's

data_census <- mutate(data_census, pov_rateT = ifelse(povpop10071==0, povpop100711mile / povpopd711mile, povpop10071 / povpopd71)) #Replace missing values with the correct rate

# Generate White demographic variables
data <- mutate(data, white_rateT = nhwht71 / pop71) #Rate within census tract
data <- mutate(data, white_rate1 = nhwht711mile / povpopd711mile) #Rate within 1 mile
data <- mutate(data, white_rate3 = nhwht713mile / povpopd713mile) #Rate within 3 miles

# Gnerate Black demographic variables
data <- mutate(data, black_rateT = blk71 / pop71) #Rate within census tract
data <- mutate(data, black_rate1 = blk711mile / povpopd711mile) #Rate within 1 mile
data <- mutate(data, black_rate3 = blk713mile / povpopd713mile) #Rate within 3 miles

# Generate Hispanic demographic variables
data <- mutate(data, hisp_rateT = hsp71 / pop71) #Rate within census tract
data <- mutate(data, hisp_rate1 = hsp711mile / povpopd711mile) #Rate within 1 mile
data <- mutate(data, hisp_rate3 = hsp713mile / povpopd713mile) #Rate within 3 miles

# Generate SNAP rates
data <- mutate(data, snap_rateT = hhsnapfam271 / hhsnapfam171) #Rate within census tract
data <- mutate(data, snap_rate1 = hhsnapfam2711mile / hh711mile) #Rate within 1 mile
data <- mutate(data, snap_rate3 = hhsnapfam2713mile / hh713mile) #Rate within 3 miles
```

```{r Generate County FIPS Variables, warning=FALSE, message=FALSE}
# Need county FIPS variable to focus analysis on Detroit metro area

# Prepare to split census tract identifyer
str(data$tract)
str(data_census$tr10fips)

# Create fips number without state identifier (first two digits)
data <- mutate(data, tract_short = substr(tract, 3, 11))
data_census <- mutate(data_census, tract_short = substr(tr10fips, 3, 11))

# Create county FIPS code variable
data <- mutate(data, county_fips = substr(tract, 3, 5))
data_census <- mutate(data_census, county_fips = substr(tr10fips, 3, 5))
```

### EXPLORING DICHOTOMOUS DATA

#### Meal Programs

```{r Meals: Distribution, warning=FALSE, message=FALSE}
# Distribution of values
pander(table(data$meals), stlye = 'rmarkdown', caption = "Number of food pantries offering meal programs.")
```

```{r Meals: Frequencies, warning=FALSE, message=FALSE}
# Relative Frequencies
pander((prop.table(table(data$meals)))*100, stlye = 'rmarkdown', caption = "Percent of food pantries offering meal programs.", digits = 3)
```

#### Groceries

```{r Groceries: Distribution, warning=FALSE, message=FALSE}
# Distribution of values
pander(table(data$groceries), stlye = 'rmarkdown', caption = "Number of food pantries offering grocery programs.")
```

```{r Groceries: Frequencies, warning=FALSE, message=FALSE}
# Relative Frequencies
pander((prop.table(table(data$groceries)))*100, stlye = 'rmarkdown', caption = "Percent of food pantries offering grocery programs.", digits = 3)
```

#### Food Related Benefits

```{r Food Benefits: Distribution, warning=FALSE, message=FALSE}
# Distribution of values
pander(table(data$food_ben), stlye = 'rmarkdown', caption = "Number of food pantries offering food-related benefits.")
```

```{r Food Benefits: Frequencies, warning=FALSE, message=FALSE}
# Relative Frequencies
pander((prop.table(table(data$food_ben)))*100, stlye = 'rmarkdown', caption = "Percent of food pantries offering food-related benefits.", digits = 3)
```

#### Non-Food Related Benefits

```{r Non-Food Benefits: Distribution, warning=FALSE, message=FALSE}
# Distribution of values
pander(table(data$nonfood_ben), stlye = 'rmarkdown', caption = "Number of food pantries offering non-food related benefits.")
```

```{r Non-Food Benefits: Frequencies, warning=FALSE, message=FALSE}
# Relative Frequencies
pander((prop.table(table(data$nonfood_ben)))*100, stlye = 'rmarkdown', caption = "Percent of food pantries offering non-food related benefits.", digits = 3)
```

### EXPLORING COUNT VARIABLES

#### Average Number of Clients Served per Month

```{r Clients: Centrality, warning=FALSE, message=FALSE}
# Centrality
pander(summary(data$clients), style = 'rmarkdown', caption = "Average number of clients served per month.")
```

```{r Clients: Histogram, warning=FALSE, message=FALSE}
# Histogram
ggplot(data, aes(x=data$clients)) +
  geom_histogram(color = "#1F3552", fill = "#4271AE") +
  scale_x_log10() +
  scale_y_continuous() +
  labs(title="Clients Served") +
  labs(x="Log of the Average Number of Clients Served per Month", y="Count")
```

### Mapping

```{r Map Link, warning=FALSE, message=FALSE}
# Link to map
compressedMap= "https://github.com/lrsulli/Project/raw/master/map/2010_Census_Tracts_v17a.zip"
```

```{r Unzip Map, warning=FALSE, message=FALSE}
# Unzip compressed map folder
temp=tempfile()
download.file(compressedMap, temp)
unzip(temp)
```

```{r Shapefiles, warning=FALSE, message=FALSE}
# Determine which shapefiles are in folder
(maps = list.files(pattern = 'shp'))
```

```{r Select Map, warning=FALSE, message=FALSE}
# Select the map
tractMap <- rgdal::readOGR("2010_Census_Tracts_v17a.shp", stringsAsFactors=F)
```

```{r Explore Map Data, warning=FALSE, message=FALSE}
names(tractMap) #check variable names
str(tractMap$LINK) #check LINK (FIPS code) variable type

# Change LINK (FIPS code) variable into an interger
tractMap$NAME=as.numeric(tractMap$LINK)
```

```{r Select Counties, warning=FALSE, message=FALSE}
# Only need counties where pantries are located (Detroit metro area)

# Keep Wayne, Macomb, Oakland, and Washtenaw Counties (FIPS = 163, 099, 125, and 161)
map_counties = subset(tractMap, CNTY_CODE=='163' | CNTY_CODE=='099' | CNTY_CODE=='125' | CNTY_CODE=='161')

data_counties = data_census[!duplicated(data_census[c('tract_short')]),] #drop duplicate tracts

# Merge map data with census data
map_counties = merge(map_counties, data_counties, by.x='LINK', by.y='tract_short', all.x=F)
```

```{r Check County Map, warning=FALSE, message=FALSE}
# Check map to determine if correct counties selected
plot(map_counties, col='black')
```

```{r Geocoding, eval=FALSE, warning=FALSE, message=FALSE}
# Only ran once because it takes awhile, wrote into an .csv file and put in Github repo

# Prepare data_address data frame
data_address$address <- do.call(paste, c(data_address[c("Street Address", "City", "State")], sep = ",")) #correct single line address format

# Got code from https://qanda.science/r/3956223_batch-geocoding-with-googleway-r-how-to.jsp

# API key for Google geocoding
api_key = "AIzaSyC2uRbBeIFBwdSiH6KH69Stx_TUoqPN0bY"

# Geocode addresses (only do once because of time)
res <- apply(data_address, 1, function(x){
  google_geocode(address = x[['address']],
                 key = api_key)
})

# Add geocode results to data_address data frame
data_address$location <- lapply(res, function(x){
  x$results$geometry$location
})

# Create latitude and longitude variables from results
data_address$location = as.character(data_address$location) #destring location variable

data_address <- mutate(data_address, lat = substr(location, 12, 20)) #get latitude numbers
data_address <- mutate(data_address, lon = substr(location, 29, 38)) #get longitude numbers

# Merge latitude and longitude with main data set to get Study ID's
map_address <- merge(data_address, data, by.x='STUDYID', by.y='id')

# Keep only necessary variables
map_address = map_address[,c('STUDYID','lat','lon')]

# Create .csv file with geocode results
write.csv(map_address, "geocoded_addresses.csv") #saved to Github repo
```

```{r Import Data: Geocoded Addresses, warning=FALSE, message=FALSE}
temp = tempfile(fileext = '.csv') #extension for Excel file
dataURL <- "https://raw.githubusercontent.com/lrsulli/Project/master/geocoded_addresses.csv" #link to data
download.file(dataURL, destfile = temp, mode = 'wb') #temporarily download file

map_address = read.csv(temp, header = TRUE, sep = ",") #get data

# Redefine latitude and longitude variables
map_address$lat = as.character(map_address$lat)
map_address$lon = as.character(map_address$lon) 
```

```{r Select Variable, warning=FALSE, message=FALSE}
# Want to plot within tract poverty rate
varToPLot=map_counties$pov_rateT
```

```{r Plot Characteristics, warning=FALSE, message=FALSE}
# Number of intervals
numberOfClasses = 5 

# Color pallete
colorForScale='YlGnBu'
colors = brewer.pal(numberOfClasses, colorForScale)

intervals <- classIntervals(varToPLot, numberOfClasses, 
                            style = "quantile",
                            dataPrecision=2)
colorPallette <- findColours(intervals, colors)
```

```{r Plot, warning=FALSE, message=FALSE}
#Plot characteristics
legendText="Poverty Rate" #legend title
shrinkLegend=0.8 #legend size
title="Poverty Rate by Census Tract"
shrinkPoints=0.35 #point size

plot(map_counties, col = 'grey') #plot background map (tracts without pantries)
plot(map_counties, col = colorPallette, main=title,border='black',add=T) #plot poverty rates

legend('topright', legend = names(attr(colorPallette, "table")), 
       fill = attr(colorPallette, "palette"), cex = shrinkLegend, 
       bty = "n",
       title=legendText)

points(map_address$lon, map_address$lat, col = "red", pch =19, cex = shrinkPoints) #add pantry locations
```
